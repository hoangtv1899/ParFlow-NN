{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net.cbrain.imports import *\n",
    "from neural_net.cbrain.data_generator import DataGenerator\n",
    "from neural_net.cbrain.models import *\n",
    "from neural_net.cbrain.legacy.losses import *\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from preprocess.preprocess_PF import *\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "#from cond_rnn import ConditionalRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set GPU usage\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_file = 'nc_file/LW_static.nc'\n",
    "precip_file = 'nc_file/LW_precip.nc'\n",
    "prev_press_file = 'nc_file/LW_prev_press.nc'\n",
    "target_satur_file = 'nc_file/LW_satur.nc'\n",
    "target_press_file = 'nc_file/LW_press.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to read forcing input data: 0.071 s\n"
     ]
    }
   ],
   "source": [
    "## forcing data\n",
    "t5 = time.time()\n",
    "forcing_input = xr.open_dataset(precip_file)\n",
    "forcing_feature_da, forcing_feature_names = create_feature_or_target_da(\n",
    "            forcing_input,\n",
    "            ['precip'],\n",
    "            0,\n",
    "            'feature',\n",
    "            flx_same_dt=True\n",
    "    )\n",
    "\n",
    "#adding channel dimension\n",
    "forcing_feature_da = forcing_feature_da.data[:,0,:,:]\n",
    "forcing_feature_da = forcing_feature_da[...,np.newaxis]\n",
    "forcing_feature_da = forcing_feature_da[np.newaxis,...]\n",
    "#merge_feature_da = merge_feature_da.data[np.newaxis,...]\n",
    "t6 = time.time()\n",
    "print('time to read forcing input data: '+str(np.around(t6-t5,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to read static data: 0.291 s\n"
     ]
    }
   ],
   "source": [
    "### static inputs\n",
    "t1 = time.time()\n",
    "static_input_xr = xr.open_dataset(static_file)\n",
    "\"\"\"\n",
    "fig,axs = plt.subplots(3,5,figsize=(16,8))\n",
    "for ii,keyi in enumerate(static_input_xr.data_vars):\n",
    "    ax = axs[ii//5,ii%5]\n",
    "    tmp_im = ax.imshow(static_input_xr[keyi][0,-1,:,:])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(tmp_im, cax=cax, orientation='vertical')\n",
    "    ax.set_title(keyi)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "time_array = precip_input_xr['time'].data\n",
    "repeat_static_input = xr.Dataset(coords={'lat':static_input_xr['lat'].data,\n",
    "                                         'lon':static_input_xr['lon'].data,\n",
    "                                         'lev':static_input_xr['lev'].data,'time':time_array})\n",
    "for k in static_input_xr.data_vars:\n",
    "    repeat_static_input[k] = (['time','lev','lat','lon'],np.tile(static_input_xr.data_vars[k],(time_array.shape[0],1,1,1)))\n",
    "\"\"\"\n",
    "static_feature_da, static_feature_names = create_feature_or_target_da(\n",
    "            static_input_xr,\n",
    "            ['slope_x','slope_y','perm','poros',\n",
    "             'rel_perm_alpha','rel_perm_N',\n",
    "             'satur_alpha','satur_N','satur_sres','satur_ssat',\n",
    "             'tensor_x','tensor_y','tensor_z','spec_storage','mannings'],\n",
    "            0,\n",
    "            'feature',\n",
    "            flx_same_dt=True\n",
    "    )\n",
    "\n",
    "t2 = time.time()\n",
    "####reshape feature\n",
    "#static_feature_da = reshape_da(static_feature_da)\n",
    "print('time to read static data: '+str(np.around(t2-t1,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to reduce static input data: 1.308 s\n"
     ]
    }
   ],
   "source": [
    "#reduce input\n",
    "t3 = time.time()\n",
    "one_layer_feats = ['slope_x','slope_y','spec_storage','mannings',\n",
    "                  'tensor_x','tensor_y','tensor_z']\n",
    "new_static_feature_da = []\n",
    "new_static_names = []\n",
    "for ii,fname in enumerate(static_feature_names.data):\n",
    "    if fname.split('_lev')[0] in one_layer_feats:\n",
    "        if int(fname[-2:]) == 0:\n",
    "            new_static_feature_da.append(static_feature_da[:,ii,:,:])\n",
    "            new_static_names.append(fname)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        new_static_feature_da.append(static_feature_da[:,ii,:,:])\n",
    "        new_static_names.append(fname)\n",
    "\n",
    "new_static_feature_da = np.stack(new_static_feature_da,axis=0)\n",
    "new_static_feature_da = np.swapaxes(new_static_feature_da,0,1)\n",
    "new_static_feature_da = np.swapaxes(new_static_feature_da,1,2)\n",
    "new_static_feature_da = np.swapaxes(new_static_feature_da,2,3)\n",
    "new_static_feature_da = np.tile(new_static_feature_da,(forcing_feature_da.shape[1],1,1,1))\n",
    "new_static_feature_da = new_static_feature_da[np.newaxis,...]\n",
    "t4 = time.time()\n",
    "print('time to reduce static input data: '+str(np.around(t4-t3,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1001, 41, 41, 407)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_static_feature_da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to read previous press input data: 1.182 s\n"
     ]
    }
   ],
   "source": [
    "#previous pressure level\n",
    "t7 = time.time()\n",
    "prev_press_input = xr.open_dataset(prev_press_file)\n",
    "prev_press_feature_da, prev_press_feature_names = create_feature_or_target_da(\n",
    "            prev_press_input,\n",
    "            ['prev_press'],\n",
    "            0,\n",
    "            'feature',\n",
    "            flx_same_dt=True\n",
    "    )\n",
    "prev_press_feature_da = np.swapaxes(prev_press_feature_da.data,1,2)\n",
    "prev_press_feature_da = np.swapaxes(prev_press_feature_da,2,3)\n",
    "prev_press_feature_da = prev_press_feature_da[np.newaxis,...]\n",
    "t8 = time.time()\n",
    "print('time to read previous press input data: '+str(np.around(t8-t7,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to read and prepare target data: 2.645 s\n"
     ]
    }
   ],
   "source": [
    "## read target files\n",
    "t6 = time.time()\n",
    "target_press_input_xr = xr.open_dataset(target_press_file)\n",
    "target_satur_input_xr = xr.open_dataset(target_satur_file)\n",
    "target_dataset = target_press_input_xr.merge(target_satur_input_xr)\n",
    "target_da, target_names = create_feature_or_target_da(\n",
    "                                                    target_dataset,\n",
    "                                                    ['press','satur'],\n",
    "                                                    0,\n",
    "                                                    'target',\n",
    "                                                    1,\n",
    "                                                    flx_same_dt=True\n",
    "                                                )\n",
    "#target_da = reshape_da(target_da)\n",
    "target_da = target_da.data[np.newaxis,...]\n",
    "target_da = np.swapaxes(target_da,2,3)\n",
    "target_da = np.swapaxes(target_da,3,4)\n",
    "t7 = time.time()\n",
    "print('time to read and prepare target data: '+str(np.around(t7-t6,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True\n",
    "pooling = True\n",
    "l2=None\n",
    "dr=None\n",
    "activation = 'relu'\n",
    "n_sample,n_timestep,nlat,nlon,n_static_feat = new_static_feature_da.shape\n",
    "static_nodes = [int(n_static_feat/8),48]\n",
    "_,n_timestep,nlat,nlon,nlev_press = prev_press_feature_da.shape\n",
    "_,_,nlat,nlon,nlev_forc = forcing_feature_da.shape\n",
    "dynamic_nodes = [16,48]\n",
    "n_sample,n_timestep,nlat,nlon,target_number = target_da.shape\n",
    "\n",
    "lr = 1e-4\n",
    "loss_dict = {\n",
    "    'mae': 'mae',\n",
    "    'mse': 'mse',\n",
    "    'log_loss': log_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to prepare model for static data: 2.864 s\n"
     ]
    }
   ],
   "source": [
    "#define the model architecture\n",
    "## first model for static data\n",
    "time8 = time.time()\n",
    "model0 = Sequential()\n",
    "model0.add(\n",
    "    ConvLSTM2D(filters=static_nodes[0],  # in convLSTM, #filters defines the output space dimensions & the capacity of the network. Similar to #units in a LSTM\n",
    "               data_format='channels_last',\n",
    "               kernel_size=(3,3), \n",
    "               padding='same',\n",
    "                input_shape = (None,nlat,nlon,n_static_feat),\n",
    "               return_sequences=True,\n",
    "    )\n",
    ")\n",
    "if batch_norm:\n",
    "    model0.add(BatchNormalization())\n",
    "if pooling:\n",
    "    model0.add(MaxPooling3D(pool_size=(1, 2, 2), \n",
    "                    padding='same', \n",
    "                    data_format='channels_last'))\n",
    "\n",
    "model0.add(TimeDistributed(Flatten()))\n",
    "model0.add(Dense(static_nodes[-1]))\n",
    "t9 = time.time()\n",
    "print('time to prepare model for static data: '+str(np.around(t9-t8,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(None, None, 48) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, None, 41, 41, 50)  822800    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 41, 41, 50)  200       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, None, 21, 21, 50)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 22050)       0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 48)          1058448   \n",
      "=================================================================\n",
      "Total params: 1,881,448\n",
      "Trainable params: 1,881,348\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to prepare model for prev press data: 0.226 s\n"
     ]
    }
   ],
   "source": [
    "##convLSTM model for previous press\n",
    "t10 = time.time()\n",
    "model1 = Sequential()\n",
    "model1.add(\n",
    "    ConvLSTM2D(filters=dynamic_nodes[0],  # in convLSTM, #filters defines the output space dimensions & the capacity of the network. Similar to #units in a LSTM\n",
    "               data_format='channels_last',\n",
    "               kernel_size=(3,3), \n",
    "               padding='same',\n",
    "                input_shape = (None,nlat,nlon,nlev_press),\n",
    "               return_sequences=True,\n",
    "    )\n",
    ")\n",
    "if batch_norm:\n",
    "    model1.add(BatchNormalization())\n",
    "if pooling:\n",
    "    model1.add(MaxPooling3D(pool_size=(1, 2, 2), \n",
    "                    padding='same', \n",
    "                    data_format='channels_last'))\n",
    "if len(dynamic_nodes) >1:\n",
    "    for h in dynamic_nodes[1:]:\n",
    "        model1.add(ConvLSTM2D(filters=h,\n",
    "                        data_format='channels_last',\n",
    "                       kernel_size=(3,3), \n",
    "                       padding='same',\n",
    "                       return_sequences=True))\n",
    "        if batch_norm:\n",
    "            model1.add(BatchNormalization())\n",
    "        if pooling:\n",
    "            model1.add(MaxPooling3D(pool_size=(1, 2, 2), \n",
    "                    padding='same', \n",
    "                    data_format='channels_last'))\n",
    "\n",
    "\n",
    "model1.add(TimeDistributed(Flatten()))\n",
    "model1.add(Dense(static_nodes[-1]))\n",
    "#model1.add(Reshape(target_shape=(1,-1)))\n",
    "t11 = time.time()\n",
    "print('time to prepare model for prev press data: '+str(np.around(t11-t10,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(None, None, 48) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, 41, 41, 16)  38080     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 41, 41, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, None, 21, 21, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, None, 21, 21, 48)  110784    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 21, 21, 48)  192       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, None, 11, 11, 48)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 5808)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 48)          278832    \n",
      "=================================================================\n",
      "Total params: 427,952\n",
      "Trainable params: 427,824\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to prepare model for forcing data: 0.224 s\n"
     ]
    }
   ],
   "source": [
    "##convLSTM model for forcing\n",
    "t12 = time.time()\n",
    "model2 = Sequential()\n",
    "model2.add(\n",
    "    ConvLSTM2D(filters=dynamic_nodes[0],  # in convLSTM, #filters defines the output space dimensions & the capacity of the network. Similar to #units in a LSTM\n",
    "               data_format='channels_last',\n",
    "               kernel_size=(3,3), \n",
    "               padding='same',\n",
    "                input_shape = (None,nlat,nlon,nlev_forc),\n",
    "               return_sequences=True,\n",
    "    )\n",
    ")\n",
    "if batch_norm:\n",
    "    model2.add(BatchNormalization())\n",
    "if pooling:\n",
    "    model2.add(MaxPooling3D(pool_size=(1, 2, 2), \n",
    "                    padding='same', \n",
    "                    data_format='channels_last'))\n",
    "if len(dynamic_nodes) >1:\n",
    "    for h in dynamic_nodes[1:]:\n",
    "        model2.add(ConvLSTM2D(filters=h,\n",
    "                        data_format='channels_last',\n",
    "                       kernel_size=(3,3), \n",
    "                       padding='same',\n",
    "                       return_sequences=True))\n",
    "        if batch_norm:\n",
    "            model2.add(BatchNormalization())\n",
    "        if pooling:\n",
    "            model2.add(MaxPooling3D(pool_size=(1, 2, 2), \n",
    "                    padding='same', \n",
    "                    data_format='channels_last'))\n",
    "model2.add(TimeDistributed(Flatten()))\n",
    "model2.add(Dense(static_nodes[-1]))\n",
    "t13 = time.time()\n",
    "print('time to prepare model for forcing data: '+str(np.around(t13-t12,3))+' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/BiasAdd:0' shape=(None, None, 48) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, None, 41, 41, 16)  9856      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 41, 41, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, None, 21, 21, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, None, 21, 21, 48)  110784    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 21, 21, 48)  192       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, None, 11, 11, 48)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 5808)        0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 48)          278832    \n",
      "=================================================================\n",
      "Total params: 399,728\n",
      "Trainable params: 399,600\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine models\n",
    "combined = concatenate([model0.output, model1.output, model2.output])\n",
    "#z = LSTM(nlat*nlon*10, activation=\"relu\")(combined)\n",
    "z = Dense(static_nodes[-1]*6,activation=\"relu\")(combined)\n",
    "z = Dense(nlat*nlon*target_number,activation=\"linear\")(combined)\n",
    "#z = Reshape(target_shape = (-1,nlat,nlon,target_number))(z)\n",
    "final_model = Model(inputs=[model0.input, model1.input, model2.input], outputs=z)\n",
    "final_model.compile(Adam(lr), loss='mse', metrics=metrics)\n",
    "#z = Dense(48, activation=\"relu\")(combined)\n",
    "#z = Dense(nlat*nlon*target_number, activation=\"linear\")(z)\n",
    "#z = Reshape(target_shape=(n_timestep,nlat,nlon,target_number))(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/BiasAdd:0' shape=(None, None, 168100) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_lst_m2d_1_input (InputLaye [(None, None, 41, 41 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_3_input (InputLaye [(None, None, 41, 41 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, None, 41, 41, 38080       conv_lst_m2d_1_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)     (None, None, 41, 41, 9856        conv_lst_m2d_3_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 41, 41, 64          conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 41, 41, 64          conv_lst_m2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_input (InputLayer) [(None, None, 41, 41 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, None, 21, 21, 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, None, 21, 21, 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)       (None, None, 41, 41, 822800      conv_lst_m2d_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, None, 21, 21, 110784      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)     (None, None, 21, 21, 110784      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 41, 41, 200         conv_lst_m2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 21, 21, 192         conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 21, 21, 192         conv_lst_m2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, None, 21, 21, 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, None, 11, 11, 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, None, 11, 11, 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 22050)  0           max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 5808)   0           max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 5808)   0           max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 48)     1058448     time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 48)     278832      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 48)     278832      time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 144)    0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 168100) 24374500    concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 27,083,628\n",
      "Trainable params: 27,083,272\n",
      "Non-trainable params: 356\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"saved_models/lstm_model_004.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1001, 41, 41, 407)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "new_static_feature_da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - ETA: 0s - loss: 1407.0593 - rmse: 37.5107 - log_loss: 1.5742 - var_ratio: 0.0279 - mean_squared_error: 1407.0593 - var_loss: 0.0011\n",
      "Epoch 00001: loss improved from inf to 1407.05933, saving model to saved_models/lstm_model_004.h5\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 1407.0593 - rmse: 37.5107 - log_loss: 1.5742 - var_ratio: 0.0279 - mean_squared_error: 1407.0593 - var_loss: 0.0011\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - ETA: 0s - loss: 1406.5629 - rmse: 37.5041 - log_loss: 1.5741 - var_ratio: 0.0237 - mean_squared_error: 1406.5629 - var_loss: 0.0011\n",
      "Epoch 00002: loss improved from 1407.05933 to 1406.56287, saving model to saved_models/lstm_model_004.h5\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 1406.5629 - rmse: 37.5041 - log_loss: 1.5741 - var_ratio: 0.0237 - mean_squared_error: 1406.5629 - var_loss: 0.0011\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - ETA: 0s - loss: 1405.4706 - rmse: 37.4896 - log_loss: 1.5739 - var_ratio: 0.0261 - mean_squared_error: 1405.4706 - var_loss: 0.0011\n",
      "Epoch 00003: loss improved from 1406.56287 to 1405.47058, saving model to saved_models/lstm_model_004.h5\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 1405.4706 - rmse: 37.4896 - log_loss: 1.5739 - var_ratio: 0.0261 - mean_squared_error: 1405.4706 - var_loss: 0.0011\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - ETA: 0s - loss: 1403.8948 - rmse: 37.4686 - log_loss: 1.5737 - var_ratio: 0.0319 - mean_squared_error: 1403.8948 - var_loss: 0.0010\n",
      "Epoch 00004: loss improved from 1405.47058 to 1403.89478, saving model to saved_models/lstm_model_004.h5\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 1403.8948 - rmse: 37.4686 - log_loss: 1.5737 - var_ratio: 0.0319 - mean_squared_error: 1403.8948 - var_loss: 0.0010\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - ETA: 0s - loss: 1401.6854 - rmse: 37.4391 - log_loss: 1.5733 - var_ratio: 0.0450 - mean_squared_error: 1401.6854 - var_loss: 0.0010\n",
      "Epoch 00005: loss improved from 1403.89478 to 1401.68542, saving model to saved_models/lstm_model_004.h5\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 1401.6854 - rmse: 37.4391 - log_loss: 1.5733 - var_ratio: 0.0450 - mean_squared_error: 1401.6854 - var_loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f148e2b80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "time_step = 30\n",
    "subset_target = target_da[:,:time_step,:,:,:]\n",
    "final_model.fit(\n",
    "        x=[new_static_feature_da[:,:time_step,:,:,:],\n",
    "           prev_press_feature_da[:,:time_step,:,:,:],\n",
    "           forcing_feature_da[:,:time_step,:,:,:]], \n",
    "        y=np.reshape(subset_target,(subset_target.shape[0],subset_target.shape[1],-1)),\n",
    "        epochs=5, batch_size=nlat*nlon,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = final_model.predict(new_merg_feature_da[:,:10,:,:,:])\n",
    "fig,axs = plt.subplots(4,5,figsize=(16,8))\n",
    "for jj,ii in enumerate([0,50,51,52,53,103,153,203,253,303,353,403,453,454,455,456,457]):\n",
    "    ax = axs[jj//5,jj%5]\n",
    "    ax.imshow(new_merg_feature_da[0,5,ii,:,:])\n",
    "    ax.set_title(new_merg_names[ii])\n",
    "#plt.imshow(new_merg_feature_da[0,5,0,:,:])\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"/glade/scratch/hoangtran/ssd_NN/NN/saved_models/lstm_model_003.h5\"\n",
    "new_model = keras.models.load_model(filepath, custom_objects={\"tf\": tf,\n",
    "                                                                    \"rmse\":rmse,\n",
    "                                                                     'log_loss': log_loss,\n",
    "                                                                     \"var_ratio\":var_ratio,\n",
    "                                                                     \"var_loss\":var_loss})\n",
    "# fit the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "subset_target = target_da[:,:time_step,:,:,:]\n",
    "new_model.fit(\n",
    "        x=[new_static_feature_da[:,:time_step,:,:,:],\n",
    "           prev_press_feature_da[:,:time_step,:,:,:],\n",
    "           forcing_feature_da[:,:time_step,:,:,:]], \n",
    "        y=np.reshape(subset_target,(subset_target.shape[0],subset_target.shape[1],-1)),\n",
    "        epochs=200, batch_size=nlat*nlon,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict([new_static_feature_da[:,:100,:,:,:],\n",
    "           prev_press_feature_da[:,:100,:,:,:],\n",
    "           forcing_feature_da[:,:100,:,:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.reshape(pred,(pred.shape[0],pred.shape[1],nlat,nlon,target_number),'C')\n",
    "fig,axs = plt.subplots(1,2,figsize=(17,8))\n",
    "im0 = axs[0].imshow(pred1[0,3,:,:,49])\n",
    "im1 = axs[1].imshow(target_da[0,3,:,:,49])\n",
    "#np.unique(pred1[0,0,:,:,:])\n",
    "axs[0].set_title('Prediction')\n",
    "axs[1].set_title('Truth')\n",
    "cb0 = fig.colorbar(im0, ax=axs[0], orientation='horizontal')\n",
    "cb1 = fig.colorbar(im1, ax=axs[1], orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[0,:2,1000:1020])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_tar_flat = np.reshape(subset_target,(subset_target.shape[0],subset_target.shape[1],-1))\n",
    "plt.imshow(subset_tar_flat[0,:2,100:120])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.vis_utils.plot_model(new_model,to_file='model2.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
